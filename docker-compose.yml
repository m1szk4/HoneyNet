version: '3.8'

services:
  # ============================================
  # HONEYPOTS - Warstwa emulacji
  # ============================================
  
  cowrie:
    image: cowrie/cowrie:latest
    container_name: cowrie
    hostname: iot-gateway
    networks:
      honeypot_net:
        ipv4_address: 172.20.0.10
    ports:
      - "22:2222/tcp"      # SSH
      - "23:2223/tcp"      # Telnet
      - "2323:2223/tcp"    # Telnet alternate
    volumes:
      - ./configs/cowrie/cowrie.cfg:/cowrie/cowrie-git/etc/cowrie.cfg:ro
      - ./configs/cowrie/userdb.txt:/cowrie/cowrie-git/etc/userdb.txt:ro
      - ./data/cowrie:/cowrie/cowrie-git/var
    environment:
      - TZ=${TZ:-UTC}
    restart: unless-stopped
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    mem_limit: 512m
    cpus: 0.5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  
  dionaea:
    image: dinotools/dionaea:latest
    container_name: dionaea
    hostname: dionaea
    networks:
      honeypot_net:
        ipv4_address: 172.20.0.11
    ports:
      - "21:21/tcp"        # FTP
      - "80:80/tcp"        # HTTP
      - "445:445/tcp"      # SMB
      - "3306:3306/tcp"    # MySQL
      - "8080:8080/tcp"    # HTTP alternate
    volumes:
      - ./configs/dionaea/dionaea.cfg:/opt/dionaea/etc/dionaea/dionaea.cfg:ro
      - ./data/dionaea:/opt/dionaea/var
    environment:
      - TZ=${TZ:-UTC}
    restart: unless-stopped
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    mem_limit: 512m
    cpus: 0.5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  
  conpot:
    image: honeynet/conpot:latest
    container_name: conpot
    hostname: conpot-ics
    networks:
      honeypot_net:
        ipv4_address: 172.20.0.12
    ports:
      - "502:502/tcp"          # Modbus
      - "161:161/udp"          # SNMP
      - "47808:47808/udp"      # BACnet
      - "623:623/udp"          # IPMI
    volumes:
      - ./data/conpot:/var/log/conpot
    environment:
      - TZ=${TZ:-UTC}
      - CONPOT_TEMPLATE=default
      - CONPOT_JSON_LOG=/var/log/conpot/conpot.json
    restart: unless-stopped
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    mem_limit: 512m
    cpus: 0.5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================
  # ANALYSIS LAYER - IDS/NSM
  # ============================================
  
  suricata:
    image: jasonish/suricata:latest
    container_name: suricata
    hostname: suricata-ids
    network_mode: "host"
    volumes:
      - ./configs/suricata/suricata.yaml:/etc/suricata/suricata.yaml:ro
      - ./configs/suricata/rules:/etc/suricata/rules:ro
      - ./data/suricata:/var/log/suricata
      - ./data/suricata/pcap:/var/log/suricata/pcap
    environment:
      - TZ=${TZ:-UTC}
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - SYS_NICE
    restart: unless-stopped
    mem_limit: ${SURICATA_MEM_LIMIT:-2g}
    cpus: ${SURICATA_THREADS:-2}
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: >
      -i eth0 
      -c /etc/suricata/suricata.yaml
      --set classification-file=/etc/suricata/classification.config
      -vvv
  
  zeek:
    image: blacktop/zeek:latest
    container_name: zeek
    hostname: zeek-nsm
    network_mode: "host"
    volumes:
      - ./configs/zeek/local.zeek:/usr/local/zeek/share/zeek/site/local.zeek:ro
      - ./configs/zeek/scripts:/usr/local/zeek/share/zeek/site/scripts:ro
      - ./data/zeek:/nsm/zeek/logs
    environment:
      - TZ=${TZ:-UTC}
    cap_add:
      - NET_ADMIN
      - NET_RAW
    restart: unless-stopped
    mem_limit: 2g
    cpus: 1.5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================
  # STORAGE LAYER
  # ============================================
  
  clickhouse:
    image: clickhouse/clickhouse-server:23.12
    container_name: clickhouse
    hostname: clickhouse
    networks:
      management_net:
        ipv4_address: 172.21.0.10
    ports:
      - "8123:8123"  # HTTP interface
      - "9000:9000"  # Native interface
    volumes:
      - ./data/clickhouse:/var/lib/clickhouse
      - ./configs/clickhouse/init-schema.sql:/docker-entrypoint-initdb.d/init.sql:ro
      - ./configs/clickhouse/users.xml:/etc/clickhouse-server/users.d/users.xml:ro
    environment:
      - TZ=${TZ:-UTC}
      - CLICKHOUSE_USER=${CLICKHOUSE_USER:-honeynet}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD:-changeme}
      - CLICKHOUSE_DB=${CLICKHOUSE_DB:-honeynet}
    restart: unless-stopped
    mem_limit: ${CLICKHOUSE_MEM_LIMIT:-3g}
    cpus: 2
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  # ============================================
  # ETL LAYER
  # ============================================
  
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    hostname: logstash
    networks:
      - management_net
    volumes:
      - ./configs/logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
      - ./configs/logstash/pipelines:/usr/share/logstash/pipeline:ro
      - ./data/cowrie:/input/cowrie:ro
      - ./data/dionaea:/input/dionaea:ro
      - ./data/conpot:/input/conpot:ro
      - ./data/suricata:/input/suricata:ro
      - ./data/zeek:/input/zeek:ro
    environment:
      - TZ=${TZ:-UTC}
      - LS_JAVA_OPTS=-Xmx1g -Xms1g
      - ANON_SALT=${ANON_SECRET_KEY}
      - CLICKHOUSE_HOST=clickhouse:8123
      - CLICKHOUSE_USER=${CLICKHOUSE_USER:-honeynet}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD:-changeme}
      - CLICKHOUSE_DB=${CLICKHOUSE_DB:-honeynet}
    depends_on:
      - clickhouse
    restart: unless-stopped
    mem_limit: 2g
    cpus: 2
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================
  # VISUALIZATION LAYER
  # ============================================
  
  grafana:
    image: grafana/grafana:10.2.0
    container_name: grafana
    hostname: grafana
    networks:
      management_net:
        ipv4_address: 172.21.0.20
    ports:
      - "3000:3000"
    volumes:
      - ./data/grafana:/var/lib/grafana
      - ./configs/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      - ./configs/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
    environment:
      - TZ=${TZ:-UTC}
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=grafana-clickhouse-datasource
      - GF_SERVER_ROOT_URL=http://localhost:3000
      - GF_SECURITY_ALLOW_EMBEDDING=true
    depends_on:
      - clickhouse
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 5s
      retries: 3

  jupyter:
    image: jupyter/scipy-notebook:latest
    container_name: jupyter
    hostname: jupyter
    networks:
      management_net:
        ipv4_address: 172.21.0.30
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data:ro
      - ./scripts/etl:/home/jovyan/scripts:ro
    environment:
      - TZ=${TZ:-UTC}
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-honeynet}
    restart: unless-stopped
    mem_limit: 1g
    cpus: 1
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# ============================================
# NETWORKS
# ============================================

networks:
  honeypot_net:
    name: honeypot_network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: ${HONEYPOT_SUBNET:-172.20.0.0/24}
          gateway: 172.20.0.1
    driver_opts:
      com.docker.network.bridge.name: br-honeypot
      com.docker.network.bridge.enable_ip_masquerade: "false"
  
  management_net:
    name: management_network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: ${MANAGEMENT_SUBNET:-172.21.0.0/24}
          gateway: 172.21.0.1
    driver_opts:
      com.docker.network.bridge.name: br-management

# ============================================
# VOLUMES (optional persistent volumes)
# ============================================

volumes:
  clickhouse_data:
    driver: local
  grafana_data:
    driver: local